To use Ollama Locally with REAL History Aware Content Generation, Follow these Steps:

Step 1: run "ollama ps" - to check if any model is already running.
	You can run "ollama stop model_name" to stop a running model.

Step 2: Just run "ollama start" to start a local server of ollama.
	Use localhost id as api of Ollama

Step 3: Just run the python file with desired Model..!!